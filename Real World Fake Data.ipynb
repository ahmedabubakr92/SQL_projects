{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5731e536",
   "metadata": {},
   "source": [
    "# Real World Fake Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4c57e",
   "metadata": {},
   "source": [
    "In this project, I'll use a dataset from \"Real World Fake Data\", import it to MySQL Workbench, clean it and then analyze it. In the end, I'll use Tableau to visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a818bfa",
   "metadata": {},
   "source": [
    "# Step 1: Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728d9dd",
   "metadata": {},
   "source": [
    "The data I'm using is from [Real World Fake Data](https://data.world/markbradbourne/rwfd-real-world-fake-data/workspace/file?filename=Call+Center.csv) which is a website that contains very interesting datasets. The one I've chosen for this project is the \"Call Center\" dataset. \n",
    "\n",
    "The Call Center dataset has 32,941 rows and 12 columns that describes calls made to various call centers. The columns of the table are:\n",
    "- id\n",
    "- customer name\n",
    "- sentiment\n",
    "- csat_score\n",
    "- call_timestamp\n",
    "- reason\n",
    "- city\n",
    "- state\n",
    "- channel\n",
    "- response_time\n",
    "- call_duration_in_minutes\n",
    "- call_center\n",
    "\n",
    "I've downloaded the Call Center datasetas a CSV file into my local drive and now we want to import it to MySQL Workbench. \n",
    "\n",
    "First, I'll start by creating a database to import that dataset to:\n",
    "\n",
    "![Creating a Database](call_center_project1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dc952",
   "metadata": {},
   "source": [
    "I've created a database called _call_center_project_. Next, to get to work on a specific database we need to select it, and we do that with the keyword \"USE\":\n",
    "![using a database](call_center_project2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f46ac7b",
   "metadata": {},
   "source": [
    "After that, I need to create a table that fit the data and match it. Let's take a look at the call center dataset in order to understand better:\n",
    "\n",
    "![csv snapshot](call_center_project3.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5e788",
   "metadata": {},
   "source": [
    "The snapshot above displays that the data contain 12 columns (attributes). To load the data into a table in the database, I need to create a table that will match it like so:\n",
    "\n",
    "![creating a table](call_center_project4.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acd655",
   "metadata": {},
   "source": [
    "Here, I've created a table called \"_calls_\", and it's been designed in a way to fit our data by matching the columns and data types. Having the columns arranged by the same order in the CSV file is not that critical as it can be managed during importing. \n",
    "\n",
    "Now that I have the \"calls\" table and it i ready to be populated with data. The MySQL Workbench makes it easy for you ti import data into a specified table and use the \"Table Data Import Wizard\". \n",
    "\n",
    "![data import](call_center_project5.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bcc08",
   "metadata": {},
   "source": [
    "The snapshot above highlights an important step in importing the data into the \"calls\" table which is to match the columns of the CSV file to the table I've created. From the looks of it, all the columns seems to match well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a649729f",
   "metadata": {},
   "source": [
    "Let's make sure that importing the data into the \"calls\" went correctly by using the following SQL command:\n",
    "\n",
    "![select statement](call_center_project6.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc43a3",
   "metadata": {},
   "source": [
    "The above statement will display all the columns in the table and limit the rows to only 10 of them. The result is as it shows in the below image:\n",
    "\n",
    "![table](call_center_project7.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8e551",
   "metadata": {},
   "source": [
    "From the resulting image, I can safely say that populating the \"calls\" table went smoothly. Now we can move to the second step which is cleaning the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5569f8",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b01653",
   "metadata": {},
   "source": [
    "There are a little minor inconveniences in our data. In the first step when I imported the data, there were two small problems:\n",
    "1. When I created the table, I've used the CHAR datatype for the call_timestamp instead of using the DATE and that is because in the CSV file, it is introduced in the mm-dd-yyyy format but in MySQL, the acceptable format is yyyy-mm-dd. Hence, using the CHAR data type instead of the DATE data type. \n",
    "\n",
    "2. In the csat_score column which means customer satisfaction score, there were empty values in the CSV file which are converted to 0 instead of null values which will lead to false statistics because the minimum score is 1 and not 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80e803",
   "metadata": {},
   "source": [
    "The steps of fixing both minor issues are as follows:\n",
    "1. In order to fix the call_timestamp, I\\ll use the  `str_to_date()` function and give it the colum and the way the date is formatted in it. The commands are shown in the below image:\n",
    "\n",
    "\n",
    "![clean data](call_center_project8.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e157e7e",
   "metadata": {},
   "source": [
    "Setting the SQL_SAFE_UPDATES off before changing the column will help in avoiding the need to specify a WHERE clause that uses a KEY column. That is why I set it off before the query and then turned it back on after the query. The resulting table after the query is shown in the image below:\n",
    "\n",
    "![reult table](call_center_project9.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0c635",
   "metadata": {},
   "source": [
    "The call_timestamp has been turned into a DATE data type successfully. Now for the second part of cleaning the data:\n",
    "2. In the csat_score, I'd like to set all the values that were NULL in the CSV file into NULL as well in the \"calls\" table. It can be done through the following command shown in the below image:\n",
    "\n",
    "![csat_score](call_center_project10.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55dc87f",
   "metadata": {},
   "source": [
    "After I've executed the above commands, let's take a look at the resulting table:\n",
    "\n",
    "![table](call_center_project11.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0013e",
   "metadata": {},
   "source": [
    "Now that I've fixed the minor inconveniences, I can move to the third step which is exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048822dc",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7a014",
   "metadata": {},
   "source": [
    "In the Exploratory Data Analysis (EDA), the purpose is to perform investigations on the data to discover any patterns, anomalies, test hypothesis and check assumptions in order to gain any insights. \n",
    "\n",
    "I'll start by checking the shape of the table, i.e., the number of rows and columns. It is done as follows:\n",
    "\n",
    "![eda1](call_center_project12.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7194ec",
   "metadata": {},
   "source": [
    "Running the first command results in the following:\n",
    "    \n",
    "![result1](call_center_project13.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a826235",
   "metadata": {},
   "source": [
    "And the second line results in the following:\n",
    "\n",
    "![result2](call_center_project14.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bb184",
   "metadata": {},
   "source": [
    "From the following results, I conclude that we loaded all the data that was in the original CSV file which consists of 32,918 records and 12 columns. \n",
    "\n",
    "Let's check the distinct values of some of the columns in the table:\n",
    "\n",
    "![distinct values](call_center_project15.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848dc90",
   "metadata": {},
   "source": [
    "Finding the different distinct values of each column gives you an idea of the type of information and categories that the column hold. For an example, the result of the first query is the following:\n",
    "\n",
    "![sentiment distinct](call_center_project16.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e6e88",
   "metadata": {},
   "source": [
    "From the above image, it shows that the \"sentiment\" column has 5 distinct values.\n",
    "\n",
    "Let's continue the exploration:\n",
    "\n",
    "![eda2](call_center_project17.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9549c6",
   "metadata": {},
   "source": [
    "The above commands, if I run any of them, will provide a result that includes the different distinct values of a specific column, the count of each category and the overall percentage of that category. An example of such result is shown in the image below:\n",
    "\n",
    "![eda result](call_center_project18.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853ad9c",
   "metadata": {},
   "source": [
    "The image shows the 5 distinct values of the \"sentiment\" column and the count of each category and its percentage. It shows that most of the sentiments recieved are negative and a small percentage out of it are postives. \n",
    "\n",
    "I'll explore which day has the most calls using the following command shown below:\n",
    "\n",
    "![calls](call_center_project19.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9586a",
   "metadata": {},
   "source": [
    "The result of the above command is shown in the image below:\n",
    "\n",
    "![calls1](call_center_project20.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d2512",
   "metadata": {},
   "source": [
    "I can see that most calls occur on Friday with a count of 5566 and the least calls occur on Sunday with a count of 4292. \n",
    "\n",
    "I'll continue with the exploration and do some aggregation on the data:\n",
    "\n",
    "![aggregations](call_center_project21.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc820c1",
   "metadata": {},
   "source": [
    "The picture above shows the aggergation commands that I've wrote in order to give us a sense and insight on the logest and shortest duration of a call for an example, or which day has the most calls and which day has less, such information can help in being better prepared and make more accurate measures when planning.\n",
    "\n",
    "Let's see one of the results of these commands:\n",
    "![aggregation result](call_center_project22.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3572aa",
   "metadata": {},
   "source": [
    "In the example shown above, I'm checking how many calls are within, above or below the Service Level Agreement time. I can see that Los Angeles/CA has the highest count of 8666 calls within SLA, 3327 calls below SLA and 1738 calls above SLA. \n",
    "\n",
    "That's it for the SQL cleaning and exploration, I'd like to create a little visualization that summarizes some of the insights that I've found during the EDA, and one of the most important tools in doing so is Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7f1b8",
   "metadata": {},
   "source": [
    "## Step 4: Data Visualization Using Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2be00b",
   "metadata": {},
   "source": [
    "Tableau is a software that can help anyone see and understand their data. Connect to almost any database, drag and drop to create visualizations, and share with a click.\n",
    "\n",
    "I've created a visualization that summarizes some of the information in the provided data. Here's an image that shows how it looks like:\n",
    "\n",
    "![dashboard](call_center_dashboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f51fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
